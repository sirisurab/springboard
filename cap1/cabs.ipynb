{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import dask.dataframe as dd\n",
    "root = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopandas import GeoDataFrame\n",
    "from geopandas import sjoin\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import LineString\n",
    "from descartes.patch import PolygonPatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prfrm_basic_prcsng = False\n",
    "prfrm_geo_prcsng = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD AND CLEAN CAB DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source : NYC TLC (Taxi and Cab Trip Data : every taxi/cab trip in NYC for 2016 and 2017)\n",
    "\n",
    "Description : Every taxi/cab trip in NYC. Useful fields are 'dropoff_datetime', 'dropoff_latitude', 'dropoff_longitude' , 'pickup_datetime', 'pickup_latitude', 'pickup_longitude', 'passenger_count'\n",
    "\n",
    "Processing :\n",
    "\n",
    "Following data issues have been addressed :\n",
    "\n",
    "    1. The dataset for 2016 and 2017 is too large and called for parallel processing techniques : The python API Dask was leveraged for this. This partitions large datsets into multiple pandas DataFrames and allows for parallel processing on them.\n",
    "\n",
    "    2. The columns 'dropoff_latitude', 'dropoff_longitude' (and 'pickup_latitude', 'pickup_longitude') required further processing in order to be readily consumable for joins (geographic) with the Stations dataset : The python geopandas library was leveraged was this purpose (This library in turn depends on shapely, fiona and rtree). 'dropoff_latitude', 'dropoff_longitude' were merged into a single 'Point' geometry (shapely.geometry.Point) and the entire datset converted to a geopandas GeoDataFrame. This allows for fairly easy (though computationally expensive in this case due to the size of the dataset) joins across datasets using the geometry attributes like, points, lines and polygons. A circle of customizable radius, centered at each station, representing the 'circles of influence' or zones for each station will be used to find intersection with taxi/cab data. (each trip will be associated with a station for the pickup point, as well as a station for the dropoff point, by finding which station-zone the points fall in)\n",
    "\n",
    "The processed data is saved in parquet format, to enable quick reading by dask in the clean_and_wrangle notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    file = root + 'cabs/all_green_1617.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    df_green = dd.read_csv(file,header=0,\n",
    "                       usecols = ['Lpep_dropoff_datetime','Passenger_count','Dropoff_longitude','Dropoff_latitude'],\n",
    "                       skipinitialspace=True,\n",
    "                       dtype={'Dropoff_latitude': 'object',\n",
    "                           'Dropoff_longitude': 'object',\n",
    "                           'Passenger_count': 'object'}\n",
    "    )[['Lpep_dropoff_datetime','Passenger_count','Dropoff_longitude','Dropoff_latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    df_green.info()\n",
    "    df_green.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    df_green = df_green.rename(columns={'Lpep_dropoff_datetime':'dropoff_datetime','Passenger_count':'passenger_count','Dropoff_longitude':'longitude','Dropoff_latitude':'latitude'}) \n",
    "    df_green.info()\n",
    "    df_green.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    file = root + 'cabs/all_yellow_1617.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    df_yellow = dd.read_csv(file,header=0,\n",
    "                       usecols = ['tpep_dropoff_datetime','passenger_count','dropoff_longitude','dropoff_latitude'],\n",
    "                       skipinitialspace=True,\n",
    "                       dtype={'dropoff_latitude': 'object',\n",
    "                           'dropoff_longitude': 'object',\n",
    "                           'passenger_count': 'object'})[['tpep_dropoff_datetime','passenger_count','dropoff_longitude','dropoff_latitude']]\n",
    "    df_yellow.info()\n",
    "    df_yellow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    df_yellow = df_yellow.rename(columns={'tpep_dropoff_datetime':'dropoff_datetime','passenger_count':'passenger_count','dropoff_longitude':'longitude','dropoff_latitude':'latitude'}) \n",
    "    df_yellow.info()\n",
    "    df_yellow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cabs_df = pd.concat([df_green,df_yellow],ignore_index=True)\n",
    "if prfrm_basic_prcsng:\n",
    "    df_green = df_green.repartition(npartitions=100)\n",
    "    df_yellow = df_yellow.repartition(npartitions=100)\n",
    "    cabs_df = dd.concat([df_green,df_yellow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cabs_df.astype(dtype={'dropoff_datetime':'datetime64','passenger_count':'int64','longitude':'float64','latitude':'float64'})\n",
    "if prfrm_basic_prcsng:\n",
    "    cabs_df['dropoff_datetime'] = cabs_df['dropoff_datetime'].map_partitions(lambda x: pd.to_datetime(x,format=\"%Y-%m-%d %H:%M:%S\", errors='coerce'),meta=('dropoff_datetime','datetime64[ns]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    cabs_df['passenger_count'] = cabs_df['passenger_count'].map_partitions(lambda x: pd.to_numeric(x, errors='coerce'),meta=('passenger_count','int64'))\n",
    "    cabs_df['longitude'] = cabs_df['longitude'].map_partitions(lambda x: pd.to_numeric(x, errors='coerce'),meta=('longitude','float64'))\n",
    "    cabs_df['latitude'] = cabs_df['latitude'].map_partitions(lambda x: pd.to_numeric(x, errors='coerce'),meta=('latitude','float64'))\n",
    "    cabs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    cabs_df['passenger_count'] = cabs_df['passenger_count'].fillna(1)\n",
    "    cabs_df['longitude'] = cabs_df['longitude'].fillna(0)\n",
    "    cabs_df['latitude'] = cabs_df['latitude'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    cabs_df = cabs_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    cabs_df = cabs_df.set_index('dropoff_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    cabs_df.info()\n",
    "    cabs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prfrm_basic_prcsng:\n",
    "    cabs_df.to_parquet(root+'cabs',\n",
    "    has_nulls=False,\n",
    "    object_encoding='json', compression='SNAPPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 3 entries, passenger_count to latitude\n",
      "dtypes: float64(2), int64(1)"
     ]
    }
   ],
   "source": [
    "if prfrm_geo_prcsng:\n",
    "    cabs_df = dd.read_parquet(root+'cabs')\n",
    "    cabs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 3 entries, passenger_count to latitude\n",
      "dtypes: float64(2), int64(1)"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:59:47</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:59:47</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:59:51</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:59:54</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:59:58</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     passenger_count  longitude  latitude\n",
       "dropoff_datetime                                         \n",
       "2017-12-31 23:59:47                4        1.0      0.40\n",
       "2017-12-31 23:59:47                7        1.0      1.18\n",
       "2017-12-31 23:59:51                6        1.0      1.40\n",
       "2017-12-31 23:59:54                7        1.0      1.42\n",
       "2017-12-31 23:59:58               11        1.0      2.69"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if prfrm_geo_prcsng:\n",
    "    cabs_df = cabs_df.loc['2016-01-01':'2017-12-31']\n",
    "    cabs_df.info()\n",
    "    #cabs_df.head()\n",
    "cabs_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>-73.962242</td>\n",
       "      <td>40.657333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>3</td>\n",
       "      <td>-73.977264</td>\n",
       "      <td>40.758514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>5</td>\n",
       "      <td>-73.944473</td>\n",
       "      <td>40.716679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>-73.999176</td>\n",
       "      <td>40.720001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>2</td>\n",
       "      <td>-73.981842</td>\n",
       "      <td>40.732407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  passenger_count  longitude   latitude\n",
       "dropoff_datetime                                       \n",
       "2016-01-01                      1 -73.962242  40.657333\n",
       "2016-01-01                      3 -73.977264  40.758514\n",
       "2016-01-01                      5 -73.944473  40.716679\n",
       "2016-01-01                      1 -73.999176  40.720001\n",
       "2016-01-01                      2 -73.981842  40.732407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if prfrm_geo_prcsng:\n",
    "    cabs_df = cabs_df.repartition(npartitions=600)\n",
    "cabs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD STATION DATA AND JOIN WITH CAB DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>POLYGON ((40.785036 -73.91203400000001, 40.784...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASTORIA BLVD</td>\n",
       "      <td>POLYGON ((40.780258 -73.917843, 40.78020984726...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30 AV</td>\n",
       "      <td>POLYGON ((40.776779 -73.92147900000001, 40.776...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BROADWAY</td>\n",
       "      <td>POLYGON ((40.77182 -73.92550799999999, 40.7717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36 AV</td>\n",
       "      <td>POLYGON ((40.766804 -73.929575, 40.76675584726...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STATION                                           geometry\n",
       "0          None  POLYGON ((40.785036 -73.91203400000001, 40.784...\n",
       "1  ASTORIA BLVD  POLYGON ((40.780258 -73.917843, 40.78020984726...\n",
       "2         30 AV  POLYGON ((40.776779 -73.92147900000001, 40.776...\n",
       "3      BROADWAY  POLYGON ((40.77182 -73.92550799999999, 40.7717...\n",
       "4         36 AV  POLYGON ((40.766804 -73.929575, 40.76675584726..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD STATION GEO DF (ALREADY PROCESSED IN STATIONS NOTEBOOK)\n",
    "if prfrm_geo_prcsng:\n",
    "    file = root + 'transit/Stations_geomerged.geojson'\n",
    "    geodf_stations = GeoDataFrame.from_file(file)[['STATION','geometry']]\n",
    "geodf_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_cab_zones(df):\n",
    "    #localdf = cabs_df[['longitude', 'latitude']].copy()\n",
    "    geometry = [Point(xy) for xy in zip(df['latitude'],df['longitude'])]\n",
    "    #df = df.drop(['latitude','longitude'],axis=1)\n",
    "    crs={'init':'epsg:4326'}\n",
    "    geodf_cabs = GeoDataFrame(cabs_df,crs=crs,geometry=geometry)\n",
    "    geodf_cabs = sjoin(geodf_cabs,geodf_stations,how='left',op='within')\n",
    "    #geodf_cabs.info()\n",
    "    return geodf_cabs.STATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 4 entries, passenger_count to STATION\n",
      "dtypes: object(1), float64(2), int64(1)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prfrm_geo_prcsng:\n",
    "    cabs_df['STATION'] = cabs_df.map_partitions(assign_cab_zones,meta=('STATION', 'object'))\n",
    "    cabs_df.info()\n",
    "    cabs_df.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if prfrm_geo_prcsng:\n",
    "    cabs_df.to_parquet(root+'cabs/geojoined',\n",
    "    has_nulls=False,\n",
    "    object_encoding='json', compression='SNAPPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
